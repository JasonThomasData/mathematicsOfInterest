{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c58fe1c",
   "metadata": {},
   "source": [
    "### Lagrange Multipliers\n",
    "\n",
    "This is a method for finding minima and maxima subject to equality constraints.\n",
    "\n",
    "[This Youtube video](https://www.youtube.com/watch?v=yuqB-d5MjZA&list=PLSQl0a2vh4HC5feHa6Rc5c0wbRTx56nF7&index=93) and the one that follows does a nice job to summarise it:\n",
    "\n",
    "![lagrangian function](Screenshot_2023-09-04_20-08-12.png)\n",
    "\n",
    "Note that the circle is the equality constraint.\n",
    "\n",
    "Then in that example:\n",
    "\n",
    "$ \\nabla f(x_m, y_m) = \\lambda g(x_m, y_m) $\n",
    "\n",
    "And $ \\lambda $ is the Lagrange Multiplier.\n",
    "\n",
    "The strategy is to take find $ \\nabla f, \\nabla g $\n",
    "\n",
    "$ \\nabla f = \\lambda \\nabla g $\n",
    "\n",
    "In the example, $ \\nabla f $ is a vector of partials:\n",
    "\n",
    "$ \\nabla f = \\left[ \\begin{matrix} 2xy \\\\ x^2 \\end{matrix} \\right] $\n",
    "\n",
    "$ \\nabla g = \\left[ \\begin{matrix} 2x \\\\ 2y \\end{matrix} \\right] $\n",
    "\n",
    "And don't forget the constraint:\n",
    "\n",
    "$ x^2 + y^2 = 1 $\n",
    "\n",
    "Then what is the value of $ \\lambda $ that satisfies the condition. It's handy to think of $ \\lambda $ as being a proportionality constant.\n",
    "\n",
    "### Lagrangian Functions\n",
    "\n",
    "Another excellent video is this one https://www.youtube.com/watch?v=hQ4UNu1P2kw&list=PLSQl0a2vh4HC5feHa6Rc5c0wbRTx56nF7&index=97\n",
    "\n",
    "It shows us how to package up the three elements of the Lagrange Multiplier method into a single function.\n",
    "\n",
    "$ \\mathcal{L}(x, y, \\lambda) = f(x, y) - \\lambda (g(x, y) - b) $\n",
    "\n",
    "where $ b $ is the RHS of the constraint that was originally given.\n",
    "\n",
    "So in the previous example, this becomes\n",
    "\n",
    "$ \\mathcal{L}(x, y, \\lambda) = (x^2 y) - \\lambda ((x^2 + y^2) - 1 ) $\n",
    "\n",
    "And now we can calculate the gradient of the Lagrangian to find the \n",
    "\n",
    "$ \\nabla \\mathcal{L} = \\vec 0 $\n",
    "\n",
    "So this is:\n",
    "\n",
    "$ \\left[ \\begin{matrix} \\frac{\\partial \\mathcal{L}}{\\partial x} \\\\ \\frac{\\partial \\mathcal{L}}{\\partial y} \\\\\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial \\lambda} \\end{matrix} \\right] = \\left[ \\begin{matrix} 0 \\\\ 0 \\\\ 0 \\end{matrix} \\right]$\n",
    "\n",
    "#### Example of using a Lagrangian function\n",
    "\n",
    "Consider:\n",
    "\n",
    "$ \\min f(x_1, x_2) = x_1 - x_2^2 $\n",
    "\n",
    "$ s.t. g(x_1, x_2) = x_1^2 + x_2^2 - 1 = 0 $\n",
    "\n",
    "The Lagrangian is:\n",
    "\n",
    "$ \\mathcal{L}(x_1, x_2, \\lambda) = x_1 - x_2^2 - \\lambda (x_1^2 + x_2^2 - 1) $\n",
    "\n",
    "But it's frequently better to change the sign of $ \\lambda $ first, meaning we also rearrange $ g $:\n",
    "\n",
    "$ \\mathcal{L}(x_1, x_2, \\lambda) = x_1 - x_2^2 + \\lambda (1 - (x_1^2 + x_2^2) $\n",
    "\n",
    "We wish to find out what happens when:\n",
    "\n",
    "$ \\nabla \\mathcal{L} = \\vec 0 $\n",
    "\n",
    "$ \\frac{\\partial \\mathcal{L}}{\\partial x_1} = 1 - 2\\lambda x_1 = 0 $ (DE 1)\n",
    "\n",
    "$ \\frac{\\partial \\mathcal{L}}{\\partial x_2} = -2x_2 - 2\\lambda x_2 = 0 $ (DE 2)\n",
    "\n",
    "$ \\frac{\\partial \\mathcal{L}}{\\partial \\lambda} = (x_1^2 + x_2^2) - 1 = 0 $ (DE 3)\n",
    "\n",
    "The sign of the constraint here doesn't matter since it's an equality constraint. Not the case for inequality.\n",
    "\n",
    "Now we can think about solving these. In other words, what are the conditions that lead to the equations being $ 0 $\n",
    "\n",
    "Take the second equation: $ -2 x_2(1+\\lambda) = 0 $.\n",
    "\n",
    "This is true if $ x_2 = 0 $ or if $ \\lambda = -1 $.\n",
    "\n",
    "Consider $ x_2 = 0 $, then in (DE 3) this implies $ x_1 = \\pm 1 $. (notice $ x_1 $ is a square)\n",
    "\n",
    "But if you consider that $ \\lambda = -1 $ and have a look at (DE 1) then it's clear that means $ x_1 = \\frac{1}{2} $\n",
    "\n",
    "That means that $ (-1,0), (1,0) $ are stationary points.\n",
    "\n",
    "Similarly we find that for $ x_1 = -\\frac{1}{2} $ that $ x_2 = \\pm \\frac{\\sqrt{3}}{2} $\n",
    "\n",
    "So that means we have another two stationary points: $ \\left(-\\frac{1}{2}, -\\frac{\\sqrt{3}}{2} \\right), \\left(-\\frac{1}{2}, \\frac{\\sqrt{3}}{2} \\right) $\n",
    "\n",
    "_Note: it is a good habbit, when you find a stationary point using two equations to check the third equality holds_.\n",
    "\n",
    "And now, we can see where the objective function touches the optimality condition below:\n",
    "\n",
    "![objective function and optimality conditions](Screenshot_2023-09-05_12-27-09.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34e5e64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Octave",
   "language": "octave",
   "name": "octave"
  },
  "language_info": {
   "file_extension": ".m",
   "help_links": [
    {
     "text": "GNU Octave",
     "url": "https://www.gnu.org/software/octave/support.html"
    },
    {
     "text": "Octave Kernel",
     "url": "https://github.com/Calysto/octave_kernel"
    },
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-octave",
   "name": "octave",
   "version": "6.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
