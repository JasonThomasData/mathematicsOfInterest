
# Standardize the data:
data {
  priorMu0   <- 1
  priorMu[1] <- 90      / 100000 # divide by 100000, since y value is scaled that way
  priorMu[2] <- 100000  / 100000
  priorMu[3] <- 1
  priorMu[4] <- 120000  / 100000
  priorMu[5] <- -150000 / 100000 # unit = 1, house = 0, unit sells $150000 less

  priorVar0   <- 1
  priorVar[1] <- 0.01 # very strong knowledge
  priorVar[2] <- 1    # weak knowledge
  priorVar[3] <- 20   # no expert knowledge
  priorVar[4] <- 0.1  # strong
  priorVar[5] <- 0.01 # very strong

  ysd <- sd(y)
  for ( i in 1:Ntotal ) {
    zy[i] <- y[i] / ysd             # standardise for use in gamma likelihood
  }
  for ( j in 1:Nx ) {
    xsd[j] <-   sd(x[,j])
    for ( i in 1:Ntotal ) {
      zx[i,j] <- ifelse( j == Nx , x[i,j] , x[i,j] / xsd[j] ) # last var is dummy, don't standardise it
    }
    
    # now standardise the prior mean and variance for this variable j
    # but not for the last variable, because it is categorical binary
    zPriorMu[j] <- ifelse( j == Nx , priorMu[j] , priorMu[j] / xsd[j] )
    zPriorVar[j] <- ifelse( j == Nx , priorVar[j] , priorVar[j] / xsd[j] )
  }

  # Specify the values of indepdenent variables for prediction
  # There are 5 predictions, and 5 values for each (over 5 variables)
  xPred[1,1] <- 600
  xPred[2,1] <- 800
  xPred[3,1] <- 1500
  xPred[4,1] <- 2500
  xPred[5,1] <- 250
  xPred[1,2] <- 2
  xPred[2,2] <- 3
  xPred[3,2] <- 2
  xPred[4,2] <- 5
  xPred[5,2] <- 3
  xPred[1,3] <- 2
  xPred[2,3] <- 1
  xPred[3,3] <- 1
  xPred[4,3] <- 4
  xPred[5,3] <- 2
  xPred[1,4] <- 1
  xPred[2,4] <- 2
  xPred[3,4] <- 1
  xPred[4,4] <- 4
  xPred[5,4] <- 1
  xPred[1,5] <- 1
  xPred[2,5] <- 0
  xPred[3,5] <- 0
  xPred[4,5] <- 0
  xPred[5,5] <- 1
}
# Specify the model for scaled data:
model {
  for ( i in 1:Ntotal ) {
    zy[i] ~ dgamma( (mu[i]^2)/zVar , mu[i]/zVar )     # likelihood
    mu[i] <- zbeta0 + sum( zbeta[1:Nx] * zx[i,1:Nx] ) # regression summation, for use in likelihood
  }

  # intercept prior
  zbeta0 ~ dnorm( priorMu0 , 1/priorVar0^(2) ) # no reason to scale
  zbeta[1] ~ dnorm(zPriorMu[1], 1/zPriorVar[1]^(2))
  zbeta[2] ~ dnorm(zPriorMu[2], 1/zPriorVar[2]^(2))
  zbeta[3] ~ dnorm(zPriorMu[3], 1/zPriorVar[3]^(2))
  zbeta[4] ~ dnorm(zPriorMu[4], 1/zPriorVar[4]^(2))
  zbeta[5] ~ dnorm(zPriorMu[5], 1/zPriorVar[5]^(2))

  # prior for var in final gamma distribution, assume no information
  zVar ~ dgamma( 0.0001 , 0.0001 )

  # Transform to original scale:
  beta[1:(Nx-1)] <- ( zbeta[1:(Nx-1)] / xsd[1:(Nx-1)] ) * ysd
  beta[Nx] <- zbeta[Nx] * ysd
  beta0 <- zbeta0*ysd
  tau <- zVar*ysd

  # Compute predictions at every step of the MCMC
  for ( i in 1:5 ) {
      pred[i] <- beta0 + beta[1] * xPred[i,1] + beta[2] * xPred[i,2] + 
           beta[3] * xPred[i,3] + beta[4] * xPred[i,4] + beta[5] * xPred[i,5]
  } 

}

