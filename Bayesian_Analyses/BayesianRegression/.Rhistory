return(panelCount)
}
}
# Original scale:
panelCount = 1
if (!is.na(compVal["beta0"])){
panelCount = decideOpenGraph( panelCount , saveName=paste0(saveName,"PostMarg") )
histInfo = plotPost( beta0 , cex.lab = 1.75 , showCurve=showCurve ,
xlab=bquote(beta[0]) , main="Intercept", compVal = as.numeric(compVal["beta0"] ))
} else {
histInfo = plotPost( beta0 , cex.lab = 1.75 , showCurve=showCurve ,
xlab=bquote(beta[0]) , main="Intercept")
}
for ( bIdx in 1:ncol(beta) ) {
panelCount = decideOpenGraph( panelCount , saveName=paste0(saveName,"PostMarg") )
if (!is.na(compVal[paste0("beta[",bIdx,"]")])) {
histInfo = plotPost( beta[,bIdx] , cex.lab = 1.75 , showCurve=showCurve ,
xlab=bquote(beta[.(bIdx)]) , main=xName[bIdx],
compVal = as.numeric(compVal[paste0("beta[",bIdx,"]")]))
} else{
histInfo = plotPost( beta[,bIdx] , cex.lab = 1.75 , showCurve=showCurve ,
xlab=bquote(beta[.(bIdx)]) , main=xName[bIdx])
}
}
panelCount = decideOpenGraph( panelCount , saveName=paste0(saveName,"PostMarg") )
histInfo = plotPost( tau , cex.lab = 1.75 , showCurve=showCurve ,
xlab=bquote(tau) , main=paste("Scale") )
panelCount = decideOpenGraph( panelCount , saveName=paste0(saveName,"PostMarg") )
histInfo = plotPost( pred , cex.lab = 1.75 , showCurve=showCurve ,
xlab="pred" , main="Prediction" ) # Added by Demirhan
# Standardized scale:
panelCount = 1
panelCount = decideOpenGraph( panelCount , saveName=paste0(saveName,"PostMargZ") )
histInfo = plotPost( zbeta0 , cex.lab = 1.75 , showCurve=showCurve ,
xlab=bquote(z*beta[0]) , main="Intercept" )
for ( bIdx in 1:ncol(beta) ) {
panelCount = decideOpenGraph( panelCount , saveName=paste0(saveName,"PostMargZ") )
histInfo = plotPost( zbeta[,bIdx] , cex.lab = 1.75 , showCurve=showCurve ,
xlab=bquote(z*beta[.(bIdx)]) , main=xName[bIdx] )
}
panelCount = decideOpenGraph( panelCount , saveName=paste0(saveName,"PostMargZ") )
histInfo = plotPost( zVar , cex.lab = 1.75 , showCurve=showCurve ,
xlab=bquote(z*tau) , main=paste("Scale") )
panelCount = decideOpenGraph( panelCount , finished=TRUE , saveName=paste0(saveName,"PostMargZ") )
#-----------------------------------------------------------------------------
}
#===============PRELIMINARY FUNCTIONS FOR POSTERIOR INFERENCES====================
myData <- read.csv("activities.csv")
myData$Type <- as.factor(myData$Type)
head(myData)
# THE DATA.
myData$Type <- as.numeric(as.factor(myData$Type))
y = myData[,"Elapsed.Time.sec."]
x = as.matrix(myData[,c("Distance.km.","ElevationGain.m.","AverageWatts","Type")])
# Some more descriptives
cat("\nCORRELATION MATRIX OF PREDICTORS:\n ")
show( round(cor(x),3) )
cat("\n")
# Specify the data in a list, for later shipment to JAGS:
dataList <- list(
x = x ,
y = y ,
Nx = dim(x)[2] ,    # variable count
Ntotal = dim(x)[1]  # observation count
)
# First run without initials!
initsList <- list(
zbeta0 = 2000,
zbeta = c(100, 1, 1, 0.5),
Var = 12000000
)
# WE WILL RUN THE MODEL WITH SCALING!
# THE MODEL.
modelString = "
# Standardize the data:
data {
ysd <- sd(y)
for ( i in 1:Ntotal ) {
zy[i] <- y[i] / ysd
}
for ( j in 1:Nx ) {
xsd[j] <-   sd(x[,j])
for ( i in 1:Ntotal ) {
zx[i,j] <- ifelse( j == Nx , x[i,j] , x[i,j] / xsd[j] ) # not to standardise the last x
# zx[i,j] <- x[i,j] / xsd[j]
}
}
# Specify the values of indepdenent variables for prediction
xPred[1] <- 20  # Distance
xPred[2] <- 250 # Elevation gain
xPred[3] <- 130 # Average watts
xPred[4] <- 1   # MTB
}
# Specify the model for scaled data:
model {
for ( i in 1:Ntotal ) {
zy[i] ~ dgamma( (mu[i]^2)/zVar , mu[i]/zVar )
mu[i] <- zbeta0 + sum( zbeta[1:Nx] * zx[i,1:Nx] )
}
# Priors vague on standardized scale:
zbeta0 ~ dnorm( 0 , 1/2^2 )
for ( j in 1:(Nx-1) ) {
zbeta[j] ~ dnorm( 0 , 1/2^2 )
}
zbeta[Nx] ~ dnorm( 0 , 1/40 )
zVar ~ dgamma( 0.01 , 0.00100 )
# Transform to original scale:
beta[1:(Nx-1)] <- ( zbeta[1:(Nx-1)] / xsd[1:(Nx-1)] ) * ysd
beta[Nx] <- zbeta[Nx] * ysd
beta0 <- zbeta0*ysd
tau <- zVar * (ysd)^2
# Compute predictions at every step of the MCMC
pred <- beta0 + beta[1] * xPred[1] + beta[2] * xPred[2] + beta[3] * xPred[3] + beta[4] * xPred[4]
}
" # close quote for modelString
# Write out modelString to a text file
writeLines( modelString , con="TEMPmodel.txt" )
parameters = c( "zbeta0" ,  "zbeta" , "beta0" ,  "beta" ,  "tau", "zVar") # Here beta is a vector!
adaptSteps = 500  # Number of steps to "tune" the samplers
burnInSteps = 10000
nChains = 2
thinSteps = 23
numSavedSteps = 5000
nIter = ceiling( ( numSavedSteps * thinSteps ) / nChains )
# Parallel run - instead of jags.model and burn-in
startTime = proc.time()
runJagsOut <- run.jags( method="parallel" ,
model="TEMPmodel.txt" ,
monitor=c( "zbeta0" ,  "zbeta" , "beta0" ,  "beta" ,  "tau", "zVar", "pred")  ,
data=dataList ,
inits=initsList ,
n.chains=nChains ,
adapt=adaptSteps ,
burnin=burnInSteps ,
sample=numSavedSteps ,
thin=thinSteps , summarise=FALSE , plots=FALSE )
codaSamples = as.mcmc.list( runJagsOut )
stopTime = proc.time()
elapsedTime = stopTime - startTime
show(elapsedTime)
save.image(file='MultRegChainsR2.RData')
diagMCMC( codaSamples , parName="tau" )
diagMCMC( codaSamples , parName="pred" )
diagMCMC( codaSamples , parName="zbeta0" )
diagMCMC( codaSamples , parName="zbeta[1]" )
diagMCMC( codaSamples , parName="zbeta[2]" )
diagMCMC( codaSamples , parName="zbeta[3]" )
diagMCMC( codaSamples , parName="zbeta[4]" )
compVal <- data.frame("beta0" = 10, "beta[1]" = NA, "beta[2]" = 5, "beta[3]" = NA, "beta[4]" =  NA, "tau" = NA , check.names=FALSE)
summaryInfo <- smryMCMC( codaSamples = codaSamples , compVal = compVal )
print(summaryInfo)
plotMCMC_HD( codaSamples = codaSamples , data = myData, xName=c("Distance.km.","ElevationGain.m.","AverageWatts","Type") ,
yName="Elapsed.Time.sec.", compVal = compVal)
# ============ Predictive check ============
coefficients <- summaryInfo[7:11,3] # Get the model coefficients out
Variance <- summaryInfo[12,3] # Get the variance out
# Since we imposed the regression model on the mean of the gamma likelihood,
# we use the model (X*beta) to generate the mean of gamma population for each
# observed x vector.
meanGamma <- as.matrix(cbind(rep(1,nrow(x)),  x)) %*% as.vector(coefficients)
# Generate random data from the posterior distribution. Here I take the
# reparameterisation back to alpha and beta.
randomData <- rgamma(n= 231,shape=meanGamma^2/Variance, rate = meanGamma/Variance)
# Display the density plot of observed data and posterior distribution:
predicted <- data.frame(elapsed = randomData)
observed <- data.frame(elapsed = y)
predicted$type <- "Predicted"
observed$type <- "Observed"
dataPred <- rbind(predicted, observed)
ggplot(dataPred, aes(elapsed, fill = type)) + geom_density(alpha = 0.2)
setwd("//wsl.localhost/Ubuntu/home/john/maths_notes/Bayesian_Analyses/BayesianRegression")
save.image(file='MultRegChainsR2.RData')
diagMCMC( codaSamples , parName="tau" )
setwd("//wsl.localhost/Ubuntu/home/john/distribution_diagrams")
plot_dist(dists$normal)
source("plot_dist.R")
plot_dist(dists$normal)
plot_dist(dists$normal)
plot_dist(dists$normal, labels = c(mean = expression(M[0]), right_sd = expression(T[0])))
plot_dist(dists$normal, labels = c(mean = expression(M[0]), right_sd = expression(T[0])), scale=3)
plot_dist(dists$normal, labels = c(mean = expression(M[0]), right_sd = expression(T[0])), scale=4)
plot_dist(dists$normal, labels = c(mean = expression(M[0]), right_sd = expression(T[0])), scale=2)
plot_dist(dists$normal, labels = c(mean = expression(M[i]), right_sd = expression(T[i])), scale=2)
plot_dist(dists$normal, labels = c(mean = expression(M[j]), right_sd = expression(T[j])), scale=2)
source("plot_dist.R")
plot_dist(dists$normal, labels = c(mean = expression(M[0]), right_sd = expression(T[0])), scale=2)
plot_dist(dists$normal, labels = c(mean = expression(M[j]), right_sd = expression(T[j])), scale=2)
plot_dist(dists$normal, labels = c(mean = expression(M[0]), right_sd = expression(T[0])), scale=2)
plot_dist(dists$normal, labels = c(mean = expression(M[j]), right_sd = expression(T[j])), scale=2)
plot_dist(dists$gamma, scale=2)
plot_dist(dists$gamma, labels= c(A = "A"), scale=2)
plot_dist(dists$gamma, labels= c(a = "A"), scale=2)
plot_dist(dists$gamma, labels= c(a = expression(A)), scale=2)
plot_dist(dists$gamma, labels= c(a = expression("A")), scale=2)
plot_dist(dists$gamma, labels= c(params = "A, B"), scale=2)
plot_dist(dists$gamma, labels= c(params = "mu[i], B"), scale=2)
plot_dist(dists$gamma, labels= c(params = "\mu[i], B"), scale=2)
plot_dist(dists$gamma, labels= c(params = c(expression(mu_i^2))), scale=2)
plot_dist(dists$gamma, labels= c(params = c(expression(mu))), scale=2)
plot_dist(dists$gamma, labels= c(params = c(expression(mu[i]))), scale=2)
plot_dist(dists$gamma, labels= c(params = c(expression(mu[i]^2))), scale=2)
plot_dist(dists$gamma, labels= c(params = c(expression(mu[i]^2)/sigma^2)), scale=2)
# likelihood
plot_dist(dists$gamma, labels= c(params = c(expression(mu[i]^2/sigma^2)), scale=2))
plot_dist(dists$gamma, labels= c(params = c(expression(mu[i]^2)/expression(sigma^2)), scale=2))
plot_dist(dists$gamma, labels= c(params = c(expression(mu[i]^2/sigma^2))), scale=2)
plot_dist(dists$gamma, labels= c(params = c(expression(mu[i]^2/sigma^2), expression(mu[i]/sigma^2))), scale=2)
plot_dist(dists$gamma, labels= c(params = c(expression(mu[i]^2/sigma^2,mu[i]/sigma^2))), scale=2)
plot_dist(dists$gamma, labels= c(params = c(expression(mu[i]^2/sigma^2,mu[i]/sigma^2))), scale=2)
plot_dist(dists$gamma, labels= c(params = c(expression(mu[i]^2/sigma^2,mu[i]/sigma^2))), scale=2)
plot_dist(dists$gamma, labels= c(params = c(expression(mu[i]^2/sigma^2), expression(mu[i]^2/sigma^2))), scale=2)
plot_dist(dists$gamma, labels= c(params = c(a = expression(mu[i]^2/sigma^2), b = expression(mu[i]/sigma^2))), scale=2)
plot_dist(dists$gamma, labels= c(params = expression(mu[i]^2/sigma^2)), scale=2)
plot_dist(dists$gamma, labels= c(params = expression(mu[i]^2/sigma^2, mu[i]^2/sigma^2)), scale=2)
plot_dist(dists$gamma, labels= c(params = expression(mu[i]^2/sigma^2 mu[i]^2/sigma^2)), scale=2)
plot_dist(dists$gamma, labels= c(params = expression(mu[i]^2/sigma^2)), scale=2)
plot_dist(dists$gamma, labels= c(params = list(mu[i]^2/sigma^2)), scale=2)
plot_dist(dists$gamma, labels= c(params = list(expression(mu[i]^2/sigma^2))), scale=2)
plot_dist(dists$gamma, labels= c(params = c(expression(mu[i]^2/sigma^2))), scale=2)
plot_dist(dists$gamma, labels= c(params = expression(list(mu[i]^2/sigma^2,mu[i]^2/sigma^2))), scale=2)
plot_dist(dists$gamma, labels= c(params = expression(list(mu[i]^2/sigma^2,mu[i]/sigma^2))), scale=2)
plot_dist(dists$normal, labels = c(mean = expression(M[j]), right_sd = expression(T[j])), scale=2)
plot_dist(dists$gamma, labels= c(params = "A, B"), scale=2)
source("~/.active-rstudio-document")
source("~/.active-rstudio-document")
graphics.off() # This closes all of R's graphics windows.
rm(list=ls())  # Careful! This clears all of R's memory!
library(ggplot2)
library(ggpubr)
library(ks)
library(rjags)
library(runjags)
source("DBDA2E-utilities.R")
setwd("//wsl.localhost/Ubuntu/home/john/distribution_diagrams/regressionProject")
graphics.off() # This closes all of R's graphics windows.
rm(list=ls())  # Careful! This clears all of R's memory!
library(ggplot2)
library(ggpubr)
library(ks)
library(rjags)
library(runjags)
source("DBDA2E-utilities.R")
graphics.off() # This closes all of R's graphics windows.
rm(list=ls())  # Careful! This clears all of R's memory!
library(ggplot2)
library(ggpubr)
library(ks)
library(rjags)
library(runjags)
source("DBDA2E-utilities.R")
setwd("//wsl.localhost/Ubuntu/home/john/maths_notes/Bayesian_Analyses/BayesianRegression")
graphics.off() # This closes all of R's graphics windows.
rm(list=ls())  # Careful! This clears all of R's memory!
library(ggplot2)
library(ggpubr)
library(ks)
library(rjags)
library(runjags)
source("DBDA2E-utilities.R")
source("providedCode.R")
myData <- read.csv("Assignment2PropertyPrices.csv")
myData$Type <- as.factor(myData$Type)
myData <- read.csv("Assignment2PropertyPrices.csv")
head(myData)
print("\nCORRELATION MATRIX OF PREDICTORS:\n ")
show( round(cor(x),3) )
print("\nCORRELATION MATRIX OF PREDICTORS:\n ")
show( round(cor(x),5) )
# THE DATA.
y = myData[,"SalePrice(100K)"]
myData <- read.csv("Assignment2PropertyPrices.csv")
y = myData[,"SalePrice(100K)"]
head(myData)
y = myData[,"SalePrice.100K."]
x = as.matrix(myData[,c("Area","Bedrooms","Bathrooms","CarParks","PropertyType")])
print("\nCORRELATION MATRIX OF PREDICTORS:\n ")
show( round(cor(x),3) )
print("\n")
cat("\nCORRELATION MATRIX OF PREDICTORS:\n ")
show( round(cor(x),3) )
cat("\n")
hist(myData$Area)
hist(myData$Bedrooms)
hist(myData$Bathrooms)
hist(myData$CarParks)
hist(myData$Area)
hist(myData$Bedrooms)
hist(myData$Bathrooms)
graphics.off() # This closes all of R's graphics windows.
rm(list=ls())  # Careful! This clears all of R's memory!
library(ggplot2)
library(ggpubr)
library(ks)
library(rjags)
library(runjags)
source("DBDA2E-utilities.R")
source("providedCode.R")
myData <- read.csv("Assignment2PropertyPrices.csv")
#myData$Type <- as.factor(myData$PropertyType)
# Above, I think that since property type is already numeric then it can stay as-is
head(myData)
# THE DATA.
y = myData[,"SalePrice.100K."]
x = as.matrix(myData[,c("Area","Bedrooms","Bathrooms","CarParks","PropertyType")])
cat("\nCORRELATION MATRIX OF PREDICTORS:\n ")
show( round(cor(x),3) )
cat("\n")
hist(myData$Area)
hist(myData$Bedrooms)
hist(myData$Bathrooms)
hist(myData$CarParks)
dataList <- list(
x = x ,
y = y ,
Nx = dim(x)[2] ,    # variable count
Ntotal = dim(x)[1]  # observation count
)
modelString = "
# Standardize the data:
data {
priorInfo[1] <- 90
priorInfo[2] <- 100000
priorInfo[3] <- 120000
priorInfo[4] <- 0
priorInfo[5] <- -150000 # unit = 1, house = 0, unit sells $150000 less
ysd <- sd(y)
for ( i in 1:Ntotal ) {
zy[i] <- y[i] / ysd
}
for ( j in 1:Nx ) {
xsd[j] <-   sd(x[,j])
for ( i in 1:Ntotal ) {
# zx[i,j] <- ifelse( j == Nx , x[i,j] , x[i,j] / xsd[j] ) # not to standardise the last x
zx[i,j] <- x[i,j] / xsd[j]
}
# zpriorInfo[j] <- ifelse( j == Nx , priorInfo[j] , priorInfo[j] / xsd[j] )
zpriorInfo[j] <- priorInfo[j] / xsd[j]
}
# Specify the values of indepdenent variables for prediction
# THERE IS A MATRIX OF VALUES TO TEST, CAN IT BE A MULTI ARRAY?
xPred[1,1] <- 600
xPred[2,1] <- 800
xPred[3,1] <- 1500
xPred[4,1] <- 2500
xPred[5,1] <- 250
xPred[1,2] <- 2
xPred[2,2] <- 3
xPred[3,2] <- 2
xPred[4,2] <- 5
xPred[5,2] <- 3
xPred[1,3] <- 2
xPred[2,3] <- 1
xPred[3,3] <- 1
xPred[4,3] <- 4
xPred[5,3] <- 2
xPred[1,4] <- 1
xPred[2,4] <- 2
xPred[3,4] <- 1
xPred[4,4] <- 4
xPred[5,4] <- 1
xPred[1,5] <- 1 # unit
xPred[2,5] <- 0
xPred[3,5] <- 0
xPred[4,5] <- 0
xPred[5,5] <- 1 # unit
}
# Specify the model for scaled data:
model {
for ( i in 1:Ntotal ) {
zy[i] ~ dgamma( (mu[i]^2)/zVar , mu[i]/zVar )
mu[i] <- zbeta0 + sum( zbeta[1:Nx] * zx[i,1:Nx] )
}
# intercept prior - what prior to give it?
zbeta0 ~ dnorm( 0 , 5 )
# other betas - since these are standard, then sd=1 would be standard.
zbeta[1] ~ dnorm(zpriorInfo[1], 1/4)
zbeta[2] ~ dnorm(zpriorInfo[2], 2)
zbeta[3] ~ dnorm(zpriorInfo[3], 6)
zbeta[4] ~ dnorm(zpriorInfo[4], 1/2)
zbeta[4] ~ dnorm(zpriorInfo[5], 1/4)
# prior for \sigma^2, used for the final gamma
modelString = "
# Standardize the data:
data {
priorInfo[1] <- 90
priorInfo[2] <- 100000
priorInfo[3] <- 120000
priorInfo[4] <- 0
priorInfo[5] <- -150000 # unit = 1, house = 0, unit sells $150000 less
ysd <- sd(y)
for ( i in 1:Ntotal ) {
zy[i] <- y[i] / ysd
}
for ( j in 1:Nx ) {
xsd[j] <-   sd(x[,j])
for ( i in 1:Ntotal ) {
# zx[i,j] <- ifelse( j == Nx , x[i,j] , x[i,j] / xsd[j] ) # not to standardise the last x
zx[i,j] <- x[i,j] / xsd[j]
}
# zpriorInfo[j] <- ifelse( j == Nx , priorInfo[j] , priorInfo[j] / xsd[j] )
zpriorInfo[j] <- priorInfo[j] / xsd[j]
}
# Specify the values of indepdenent variables for prediction
# THERE IS A MATRIX OF VALUES TO TEST, CAN IT BE A MULTI ARRAY?
xPred[1,1] <- 600
xPred[2,1] <- 800
xPred[3,1] <- 1500
xPred[4,1] <- 2500
xPred[5,1] <- 250
xPred[1,2] <- 2
xPred[2,2] <- 3
xPred[3,2] <- 2
xPred[4,2] <- 5
xPred[5,2] <- 3
xPred[1,3] <- 2
xPred[2,3] <- 1
xPred[3,3] <- 1
xPred[4,3] <- 4
xPred[5,3] <- 2
xPred[1,4] <- 1
xPred[2,4] <- 2
xPred[3,4] <- 1
xPred[4,4] <- 4
xPred[5,4] <- 1
xPred[1,5] <- 1 # unit
xPred[2,5] <- 0
xPred[3,5] <- 0
xPred[4,5] <- 0
xPred[5,5] <- 1 # unit
}
# Specify the model for scaled data:
model {
for ( i in 1:Ntotal ) {
zy[i] ~ dgamma( (mu[i]^2)/zVar , mu[i]/zVar )
mu[i] <- zbeta0 + sum( zbeta[1:Nx] * zx[i,1:Nx] )
}
# intercept prior - what prior to give it?
zbeta0 ~ dnorm( 0 , 5 )
# other betas - since these are standard, then sd=1 would be standard.
zbeta[1] ~ dnorm(zpriorInfo[1], 1/4)
zbeta[2] ~ dnorm(zpriorInfo[2], 2)
zbeta[3] ~ dnorm(zpriorInfo[3], 6)
zbeta[4] ~ dnorm(zpriorInfo[4], 1/2)
zbeta[4] ~ dnorm(zpriorInfo[5], 1/4)
# prior for sigma^2, used for the final gamma
zVar ~ dgamma( 0.01 , 0.00100 )
# Transform to original scale:
# IF WE DON'T SCALE FINAL VAR
# beta[1:(Nx-1)] <- ( zbeta[1:(Nx-1)] / xsd[1:(Nx-1)] ) * ysd
# beta[Nx] <- zbeta[Nx] * ysd
beta[1:Nx] <- ( zbeta[1:Nx] / xsd[1:Nx] ) * ysd
beta0 <- zbeta0*ysd
tau <- zVar * (ysd)^2
# Compute predictions at every step of the MCMC
# for ( j in 1:Nx ) {
# TRY A RECUCED SET FIRST
for ( j in 1:1 ) {
pred[j] <- beta0 + beta[1] * xPred[1,j] + beta[2] * xPred[2,j] + beta[3] * xPred[3,j] + beta[4] * xPred[4,j] + beta[5] * xPred[5,j]
}
}
" # close quote for modelString
# Write out modelString to a text file
writeLines( modelString , con="TEMPmodel.txt" )
adaptSteps = 500  # Number of steps to "tune" the samplers
burnInSteps = 10000
nChains = 2
thinSteps = 23
numSavedSteps = 5000
nIter = ceiling( ( numSavedSteps * thinSteps ) / nChains )
startTime = proc.time()
runJagsOut <- run.jags( method="parallel" ,
model="TEMPmodel.txt" ,
monitor=c( "zbeta0" ,  "zbeta" , "beta0" ,  "beta" ,  "tau", "zVar", "pred")  ,
data=dataList ,
inits=initsList ,
n.chains=nChains ,
adapt=adaptSteps ,
burnin=burnInSteps ,
sample=numSavedSteps ,
thin=thinSteps , summarise=FALSE , plots=FALSE )
# Parallel run - instead of jags.model and burn-in
startTime = proc.time()
runJagsOut <- run.jags( method="parallel" ,
model="TEMPmodel.txt" ,
monitor=c( "zbeta0" ,  "zbeta" , "beta0" ,  "beta" ,  "tau", "zVar", "pred")  ,
data=dataList ,
#inits=initsList ,
n.chains=nChains ,
adapt=adaptSteps ,
burnin=burnInSteps ,
sample=numSavedSteps ,
thin=thinSteps , summarise=FALSE , plots=FALSE )
# Parallel run - instead of jags.model and burn-in
startTime = proc.time()
runJagsOut <- run.jags( method="parallel" ,
model="TEMPmodel.txt" ,
monitor=c( "zbeta0" ,  "zbeta" , "beta0" ,  "beta" ,  "tau", "zVar", "pred")  ,
data=dataList ,
#inits=initsList ,
n.chains=nChains ,
adapt=adaptSteps ,
burnin=burnInSteps ,
sample=numSavedSteps ,
thin=thinSteps , summarise=FALSE , plots=FALSE )
xsd[j] <-   sd(x[,j])
xsd[1] <-   sd(x[,1])
sd(x[,1])
priorInfo <- 90
priorInfo / sd(x[,1])
priorInfo <- 100000
priorInfo / sd(x[,2])
sd(x[,2])
