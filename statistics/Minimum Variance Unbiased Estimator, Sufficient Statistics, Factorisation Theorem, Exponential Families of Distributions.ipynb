{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d337b2a",
   "metadata": {},
   "source": [
    "### Minimum Variance Unbiased Estimator\n",
    "\n",
    "This is linked to Sufficient Statistics.\n",
    "\n",
    "A statistic is essentially a way of reducing data.\n",
    "\n",
    "EG: the sample mean, is a statistic taken from the sample. It is a form of reducing the data.\n",
    "\n",
    "#### Sufficient statistics\n",
    "\n",
    "A sample statistic the relates to a population parameter is sufficient if it contains all of the information regarding the population parameter.\n",
    "\n",
    "Let: $ X $ be a random sample.\n",
    "\n",
    "$ T(X) $ is a sufficient statistic for $ \\theta $ if the conditional density of $ X $ given $ T(X) $ doesn't depend on $ \\theta $.\n",
    "\n",
    "The sufficient statistic exhausts all information about $ \\theta $ that is contained in the sample.\n",
    "\n",
    "#### Ancillary statistics\n",
    "\n",
    "These are at the other extreme, compared to Sufficient Statistics.\n",
    "\n",
    "The distribution of one doesn't depend on $ \\theta $. That implies that the Ancillary Statistic provides no information about $ \\theta $\n",
    "\n",
    "A related concept is the Basu Theorem.\n",
    "\n",
    "#### Sufficient Statistics, applied\n",
    "\n",
    "Recall the definition for conditional probability:\n",
    "\n",
    "$ P(X | Y) = \\frac{P(X \\cap Y)}{P(Y)} $\n",
    "\n",
    "And apply the requirement that the conditional pdf is independent of $ \\theta $\n",
    "\n",
    "$ P(X | T(X)=t) = \\frac{P(X \\cap \\{T(X) = t\\})}{P(T(X) = t)} $\n",
    "\n",
    "This is equivalent to:\n",
    "\n",
    "$ t = T(x_1, x_2, ..., x_n) $\n",
    "\n",
    "$ h(x|t) = \\frac{f(x_1, \\theta)f(x_2, \\theta)...f(x_n, \\theta)}{g(t,\\theta)} $\n",
    "\n",
    "_Don't be alarmed about the existence of $ \\theta $ in the equation, it might cancel._\n",
    "\n",
    "If you use the second equation (for example with a Binomial distribution) then if you cancel everything out and you are left with no $ \\theta $, then your condition density doesn't rely on $ \\theta $. Therefore, the statistic is found to be a sufficient statistic.\n",
    "\n",
    "Example using Bournoulli ~20:00 in lecture 5(1)a.\n",
    "\n",
    "#### Factorisation Theorem\n",
    "\n",
    "This is another way to check if a statistic is sufficient. Given a joint pmf or pdf (of a sample), we can check for it being sufficient by inspection of pdf/pmf.\n",
    "\n",
    "A statistic $ T(X) $ is sufficient for $ \\theta $ if we can find two non-negative functions $ g, h $ such that the joint pmf or pdf of the sample can be factored as\n",
    "\n",
    "$ f(x, \\theta) = g(T(X); \\theta)h(x) $\n",
    "\n",
    "where the function $ h(x) $ does not depend on $ \\theta $, and the function $ g(T(X); \\theta) $ depends only on $ \\theta, x $ through the sufficient statistic.\n",
    "\n",
    "##### Using factorisation theorem to find sufficient statistic\n",
    "\n",
    "This example assumes that we know $ X $ does not depend on $ \\theta $\n",
    "\n",
    "Given a Bournoulli Distribution, which has the pdf:\n",
    "\n",
    "$ f(x; \\theta) = \\theta^x(1-\\theta)^{1-x}, x = 0,1; 0 < \\theta < 1 $\n",
    "\n",
    "Since the statistic $ X $ doesn't depend on the population parameter, then:\n",
    "\n",
    "$ f(x_1, x_2, x_3, ..., f_n) = \\prod_{i=1}^n f(x_1; \\theta) $\n",
    "\n",
    "$ f(x; \\theta) = \\theta^x(1-\\theta)^{1-x}, x = 0,1; 0 < \\theta < 1 $\n",
    "\n",
    "For reasons I'm yet to understand it pans out to be this next line:\n",
    "\n",
    "$ = \\theta^{\\sum_{i=1}^n x_i}(1 - \\theta)^{n - \\sum_{i=1}^n x_i} $\n",
    "\n",
    "$ = \\left(\\frac{\\theta}{(1-\\theta)}\\right)^{\\sum_{i=1}^n x_i}(1 - \\theta)^{n} \\times 1 $\n",
    "\n",
    "$ h(x) = 1 $\n",
    "\n",
    "$ g(T(X); \\theta) = \\left(\\frac{\\theta}{(1-\\theta)}\\right)^{\\sum_{i=1}^n x_i}(1 - \\theta)^{n} $\n",
    "\n",
    "By the factorisation theorem, the sufficient statistic is $ T(X) = \\sum_{i=1}^n x_i $\n",
    "\n",
    "##### The same lecture 5(I)a gives some details about doing the same for a continuous distribution\n",
    "\n",
    "### Exponential family of distributions\n",
    "\n",
    "If a family of distributions has the form:\n",
    "\n",
    "$ f(x; \\theta) = h(x)c(\\theta)exp \\left(\\sum_{i=1}^k w_i(\\theta) t_i(x) \\right), a < x < b $\n",
    "\n",
    "Then we can say it is an exponential family of distributions.\n",
    "\n",
    "Note that $ t, h $ must be functions of $ x $ alone and $ c, w $ must be functions of $ \\theta $ alone.\n",
    "\n",
    "$ x, \\theta $ could be multivariate instead of univariate.\n",
    "\n",
    "The Binomial and Normal distributions are members of the the exponential family (under certain conditions).\n",
    "\n",
    "The Poisson and Gamma distributions are members of the exponential family, but I'm not sure if they are always in it or only under some conditions.\n",
    "\n",
    "HOMEWORK: REWRITE ALL OF THESE 4 INTO THE EXPONENTIAL FAMILY DISTRIBUTION FORMS.\n",
    "\n",
    "~ 4:00 5(I)b\n",
    "\n",
    "#### Obtaining sufficient statistics for unknown population parameters in an exponential family of distributions\n",
    "\n",
    "If we can show that a random sample has the form:\n",
    "\n",
    "$ f(x; \\theta) = h(x)c(\\theta)exp \\left(\\sum_{i=1}^k w_i(\\theta) t_i(x) \\right), a < x < b $\n",
    "\n",
    "With unknown parameters $ \\theta = \\{ \\theta_1, \\theta_2, ... \\theta \\} $\n",
    "\n",
    "Then:\n",
    "\n",
    "$ T(X) = \\{ \\sum_{i=1}^n t_1(X_i), \\sum_{i=1}^n t_2(X_i), ..., \\sum_{i=1}^n t_k(X_i) \\} $ \n",
    "\n",
    "It's important that the subscript of $ t $ goes up to $ k $ not $ n $.\n",
    "\n",
    "##### Example, given a exponential family\n",
    "\n",
    "Given some exponential family, where the pdf or pmf has the form\n",
    "\n",
    "$ f(x; \\theta) = h(x)c(\\theta)exp \\left(\\sum_{i=1}^k w_i(\\theta) t_i(x) \\right), a < x < b $\n",
    "\n",
    "Then:\n",
    "\n",
    "$ f(x; \\theta) = \\prod_{i=1}^n f_i(x_i; \\theta)$\n",
    "\n",
    "$ f(x; \\theta) = \\prod_{i=1}^n h(x)c(\\theta)exp \\left(\\sum_{i=1}^k w_i(\\theta) t_i(x) \\right)$\n",
    "\n",
    "And there, at ~12:00, lecture 5(I)b my comprehension ceases.\n",
    "\n",
    "#### Sufficient statistic for distributions, using the above result\n",
    "\n",
    "Exponential family of binomial distributions, the sufficient statistic is:\n",
    "\n",
    "$ T(X) = \\sum_{i=1}^n X_i $\n",
    "\n",
    "For $ \\rho $ in the binomial distribution\n",
    "\n",
    "Exponential family of normal distributions, the sufficient statistic is:\n",
    "\n",
    "$ T(X) = (\\sum_{i=1}^n X_i, \\sum_{i=1}^n X_i^2) $\n",
    "\n",
    "For $ (\\mu, \\sigma^2) $ in the normal distribution\n",
    "\n",
    "DO THE POISSON AND GAMMA, TO MAKE SURE YOU UNDERSTAND.\n",
    "\n",
    "THE DISTRIBUTION PDF/PMFs ARE GIVEN IN 15:21 OF LECTURE 5(I)b\n",
    "\n",
    "THE PROCESS WOULD BE TO CONVERT THEM TO THE EXP FAMILY FORM AND THEN REPRODUCE FORMER STEPS.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df717622",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
